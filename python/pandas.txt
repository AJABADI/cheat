# Excluding / selecting columns
df = pd.DataFrame(np.arange(15).reshape(5, 3), columns=list('ABC'))
sel = list('AC')
df_sel = df[sel]
df_unsel = df[[c for c in df.columns if c not in sel]]
* Alternative: df.set_index()

# IO
read_hdf('file', 'groupname')
read_csv(file, ...)
  nrows // max number of rows to be read
  sep // delimiter
  usecols // select columns by name

# Index
columns // column index
index // row index
set_index(column, inplace=False) // use column as index
reset_index(inplace=False) // convert index to columns
index.values[0] = 'new_label' // rename index; rename column/row
df.columns = ['c1', 'c2'] // rename columns

## Indexing
df.loc[(r1, r2), c] // row by levels (r1, r2), column c
df.loc[r1, c] // only first level
df.loc[r1].loc[r2] == df.loc[(r1, r2)]

## Creating index
i = Index(array, dtype=)
i = MultiIndex.from_tuples([array1, array2], names=[name1, name2])
df = DataFrame(array, index=i)
df.index = i

## Multiindex
i = df.columns  // multiindex for columns
i.get_level_values(k) // get column labels level k
i.droplevel(k) // remove level k
df.columns = df.columns.droplevel(k)

# Missing values
count() // # non-missing
isnull()
fillna(0)
dropna(axis=) // drop axis with missing values
interpolate() // fill missing values by interpolation
count(axis=)  // count # non-null elements

# Selection, filtering
s = df.pos  // selection based on series
s > 0 // returns boolean vector
(s > 0) & (s < 5) // boolean operator: brackets; &, |, ~ instead of and, or, not
s[(s > 0) & (s < 5)]  // section series
df[(df.pos > 0) & (df.pos < 5)] // selection data frame
s.isin([3, 5, 5]) // select single values
s.where(s > 5)  // sets entries s <= 5 to NaN
s.where(s < 5, 10)  // sets entries s <= 5 to 10
s.mask(s > 5) // sets entries s > 5 to Nan


# pandas printoptions
pd.set_option('display.width', 150) 
pd.set_option('display.height', 150)
pd.set_option('display.max_columns', 150)
pd.set_option('display.max_rows', 150)

# Melting and reshaping
df.pivot_table(rows=, cols=, values=) // list -> matrix
pd.melt(matrix, ids_vars=, value_vars=, var_name) // matrix -> list


# Convert to numpy array / structured array
t = df.values // unstructured
t = df.to_records() //structured
  * encodes str as 'O', i.e. numpy object
  * not supported by hdf5

# Iterating
for row in df.iterrows():
  print row[colindex]
for col in df.iteritems():
  print col[rowindex]
df.iterrows() // iterate over rows
df.iteritems()  // iterator over columns
-> return tuple iterator

# R datasets
import numpy.rpy.common as com
com.load_data('mtcars')


# Grouping
g = df.groupby(['c1', 'c2'])
g.groups  // groups as dictionary
g.groups.keys() // group names
g.get_group((g1, g2)) // query group by tuple
g.ngroups // number of groups
for name, value in g: // iterate over groups
g.count()
g.describe()
g.fist()  // first element of each group
g.last()  // last element of each group
g.size()  // # group members
g['c1', 'c2'] // select columns
g.aggregate([fun1, fun2]) // summarize functions as single value
g.aggregate({label:fun})
g.transform(lambda x: np.mean(x)) // group specific modification; same size as group
g.filter(lambda x: np.mean(x) > 0.5)  // return only members of groups that satisfy constraint
g.apply(lambda df: pd.DataFrame({...})  // apply arbitrary function to groups

# Summary
df.head() / df.tail()
df.columns / df.index
df.describe()

# Comparing DataFrames
df.all(axis=0)
df.all().all()
import pandas.util.testing as pt
pt.assert_frame_equal(df1, df2)

# Sql
import sqlite3 as sql
import pandas.io.sql as psql
con = sql.connect()
df = psql.read_sql('SELECT * ', con, index_col=)


# DataFrame
DataFrame(columns=['c1', 'c2'], index=['r1', 'r2'], dtype=bool)
  columns=  // column labels
  index=  // row labels
DataFrame({'id':[0, 1, 2], 'value':[1, 2, 3]})  // from dict
DataFrame.from_dict(dict) // same as before
DataFrame(np.ones((n, m)), columns=)  // from numpy array
DataFrame.from_csv

## Misc
df.values // numpy array used internally
df.values.nbytes  // memory usage

## selection
.loc[rowlabel, collabel]  // purely label based
.iloc[rowindex, colindex] // purely index based
.ix[rowlabel, colindex] // mixed label index
.at[rowlabel, collabel] // scalar label based
.iat[rowindex, colindex]  // scalar index based
df[a & b | c & ~d]  // boolean indexing by rows
df.ix[:, a & b] // boolean indexing by columns

## hdf5
df.to_hdf('file', 'groupname')
df = pd.read_hdf('file', 'groupname')

# Missing values
dropna(...)  // drop columns with nan
  axis=0/1
  how=any/all
  inplace=F
isnull(), notnull()

