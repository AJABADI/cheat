# LSF
* Load Sharing Facility
* http://www.ebi.ac.uk/systems-srv/public-wiki/index.php/EBI_Good_Computing_Guide
* python inferface: https://pypi.python.org/pypi/bsub/0.3.3


# lsmake
* run make targets in parallel
* default: run on local host with 1 cpu
lsmake [makeoptions] [target] // 
-j n  // use n cpus
-c m  // run m jobs per cpu
-R resources
-m hostname
-V  // verbose, print hosts
-y  // print summary at the end

# bsub
-R "rusage[mem=100]" -M 100 // request 100 MB
-R 'select[panfs_nobackup_research]'  // select filesystem
-R "select[model=XeonE52670]" // cpu model
-n ncpu // tell LSF number of cpus, memory x ncpu
-o  file  // append stdout to file
    file%J  // substitute %J by job id
-e  file  // append stderr to file
-oo, -ee  // overwrite instead of append
-cwd dir  // change to dir before executing command, logs in dir
-XF // X11 forwarding

# queues
-q research-rh6  // research queue (default)
-q production-rh6 // production jobs run with higher priority
-q dungeon  // long runnning (>7 days) jobs

## Interactive job
bsub -Is bash // interactive tmux
bsub -Is tmux // interactive tmux
bsub -Ip ipython console  // interactive console
bsub -Ip -XF ipython console  // interactive job with X11 forwarding


# bjobs
bjobs -l ID  // detailed information
bjobs -a  // show all (including finished jobs)

# bkill
bkill 0 // kill all jobs
bkill -h /groupname 0 // kill all jobs of group


# Groups
bgadd -L 2 /groupname // group with 2 slots (max 2 jobs)
bgmod -L 10 /groupname  // change slots
bjgroup -s /groupname // get info
bsub -g /groupname -o …. -e …. // submit using group
bkill -g /groupname 0 // kill jobs of group


# General infos
lsid  // show current cluster
lsload -E // show current load
lshosts // show spec of nodes
bqueues // show all queues

# EBI file exchange
http://www.ebi.ac.uk/systems-srv/mp/file-exchange/
* 500 MB single files
* 2.5 GB total
* Alternative: EBI Google Drive

# EBI backups
* cd ~/.snapshot // invisible by ls -a
